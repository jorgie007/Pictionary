{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['okay', 'peace', 'thumbs up', 'thumbs down', 'call me', 'stop', 'rock', 'live long', 'fist', 'smile']\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 449, y: 499\n",
      "x: 0, y: 499\n",
      "x: 452, y: 499\n",
      "x: 0, y: 499\n",
      "x: 510, y: 472\n",
      "x: 0, y: 497\n",
      "x: 515, y: 463\n",
      "x: 0, y: 499\n",
      "x: 514, y: 463\n",
      "x: 0, y: 499\n",
      "x: 524, y: 463\n",
      "x: 0, y: 492\n",
      "x: 521, y: 471\n",
      "x: 0, y: 490\n",
      "x: 521, y: 471\n",
      "x: 0, y: 492\n",
      "x: 522, y: 499\n",
      "x: 0, y: 490\n",
      "x: 437, y: 499\n",
      "x: 0, y: 495\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 4, y: 499\n",
      "x: 1, y: 499\n",
      "x: 3, y: 499\n",
      "x: 3, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 1, y: 499\n",
      "x: 1, y: 499\n",
      "x: 0, y: 499\n",
      "x: 2, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 0, y: 499\n",
      "x: 1, y: 499\n",
      "x: 4, y: 499\n",
      "x: 7, y: 499\n",
      "x: 13, y: 499\n",
      "x: 13, y: 499\n",
      "x: 13, y: 499\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import cv2 as cv\n",
    "import mediapipe as mp\n",
    "import pyautogui as pg\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "pg.FAILSAFE = False\n",
    "\n",
    "# this is some preliminary work\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# this is necessary for the \"drawing\" screen inside the camera angle\n",
    "margin = 0.2\n",
    "max_screen_width, max_screen_height = 900, 500# pg.size()\n",
    "\n",
    "#draw_width_offset = int(0.5 * margin * max_screen_width)\n",
    "#draw_height_offset = int(0.5 * margin * max_screen_height)\n",
    "\n",
    "draw_width_offset = 0.5 * margin\n",
    "draw_height_offset = 0.5 * margin\n",
    "\n",
    "# The draw window is a subset of the frame such that we can also reach the edges of the drawing board\n",
    "#draw_window_width, draw_window_height = int((1- margin) * max_screen_width), int((1-margin) * max_screen_height)\n",
    "draw_window_width, draw_window_height = (1- margin), (1-margin)\n",
    "\n",
    "\n",
    "# this is necessary for the maximum poisition of the mouse\n",
    "max_screen_width = max_screen_width - 1\n",
    "max_screen_height = max_screen_height - 1\n",
    "\n",
    "# Load the gesture recognizer model\n",
    "model = load_model('mp_hand_gesture')\n",
    "\n",
    "# Load class names\n",
    "f = open('gesture.names', 'r')\n",
    "classNames = f.read().split('\\n')\n",
    "f.close()\n",
    "print(classNames)\n",
    "\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "with mp_hands.Hands(\n",
    "    model_complexity=0,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    frame_width, frame_height, c = image.shape\n",
    "    className = \"\"\n",
    "\n",
    "\n",
    "    #print(f\"x: {frame_width}, y: {frame_height}\")\n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    results = hands.process(image)\n",
    "\n",
    "    # Draw the hand annotations on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
    "    if results.multi_hand_landmarks:\n",
    "      landmarks = []\n",
    "      for hand_landmarks in results.multi_hand_landmarks:\n",
    "        #print(hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x)\n",
    "        #print(hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].y)\n",
    "\n",
    "        # Firstly, retrieve the coordinates of the fingers on the frame (relative coordinates in range [0,1])\n",
    "        # the coordinates are calculated with the upper left corner as origin (0,0)\n",
    "\n",
    "        # in this case it should start at 0\n",
    "        if hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x > 1:\n",
    "          finger_coor_x = 0\n",
    "        elif hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x < 0:\n",
    "          finger_coor_x = 1\n",
    "        # get the finger coorindates, adjust x value because pyautogui uses a different method\n",
    "        #else: finger_coor_x = int((1 - hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x) * max_screen_width)\n",
    "        else: finger_coor_x = 1 - hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x\n",
    "\n",
    "        if hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].y > 1:\n",
    "          #finger_coor_y = max_screen_height\n",
    "          finger_coor_y = 1\n",
    "        elif hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].y < 0:\n",
    "          finger_coor_y = 0\n",
    "        #else: finger_coor_y = int(hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].y * max_screen_height)\n",
    "        else: finger_coor_y = hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].y \n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # finger position is within or outside the window, calculate new coordinates\n",
    "        if finger_coor_x < draw_width_offset: \n",
    "          relative_x = 0\n",
    "          draw_x = int(relative_x * max_screen_width)\n",
    "        elif finger_coor_x > max_screen_width - draw_width_offset:\n",
    "          relative_x = 1\n",
    "          draw_x = int(relative_x * max_screen_width)\n",
    "        else:\n",
    "          relative_x = (finger_coor_x - draw_width_offset) / draw_window_width\n",
    "          draw_x = int(relative_x * max_screen_width)\n",
    "\n",
    "        if finger_coor_y < draw_height_offset: \n",
    "          relative_y = 0\n",
    "          draw_y = int(relative_y * max_screen_height)\n",
    "        elif finger_coor_y > max_screen_height - draw_height_offset:\n",
    "          relative_y = 1\n",
    "          draw_y = int(relative_y * max_screen_height)\n",
    "        else:\n",
    "          relative_y = (finger_coor_y - draw_height_offset) / draw_window_height\n",
    "          draw_y = int(relative_y * max_screen_width)\n",
    "        \"\"\"\n",
    "\n",
    "        if finger_coor_x < draw_width_offset: \n",
    "          relative_x = 0\n",
    "          draw_x = relative_x\n",
    "        elif finger_coor_x > draw_window_width + draw_width_offset:\n",
    "          relative_x = 1\n",
    "          draw_x = relative_x \n",
    "        else:\n",
    "          relative_x = (finger_coor_x - draw_width_offset) / draw_window_width\n",
    "          draw_x = relative_x\n",
    "\n",
    "        if finger_coor_y < draw_height_offset: \n",
    "          relative_y = 0\n",
    "          draw_y = relative_y\n",
    "        elif finger_coor_y > draw_window_height + draw_height_offset:\n",
    "          relative_y = 1\n",
    "          draw_y = relative_y\n",
    "        else:\n",
    "          relative_y = (finger_coor_y - draw_height_offset) / draw_window_height\n",
    "          draw_y = relative_y\n",
    "\n",
    "        draw_x, draw_y = int(draw_x * max_screen_width), int(draw_y * max_screen_height)\n",
    "        \n",
    "        for lm in hand_landmarks.landmark:\n",
    "          # print(id, lm)\n",
    "          lmx = int(lm.x * frame_width)\n",
    "          lmy = int(lm.y * frame_height)\n",
    "\n",
    "          landmarks.append([lmx, lmy])\n",
    "        # Predict gesture\n",
    "        if len(landmarks) == 21:\n",
    "          prediction = model.predict([landmarks])\n",
    "          # print(prediction)\n",
    "          classID = np.argmax(prediction)\n",
    "          className = classNames[classID]\n",
    "    \n",
    "\n",
    "        print(f\"x: {draw_x}, y: {draw_y}\")\n",
    "        #pg.moveTo(draw_x, draw_y)\n",
    "        if className == \"fist\":\n",
    "          pg.click()\n",
    "        #print(f\"finger x: {finger_coor_x}, finger y: {finger_coor_y}\")\n",
    "        #print(f\"draw x: {draw_x}, draw y: {draw_y}\")\n",
    "\n",
    "        #print(\"----------------\")\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            hand_landmarks,\n",
    "            mp_hands.HAND_CONNECTIONS,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "    #cv.putText(image, className, (10, 50), cv.FONT_HERSHEY_SIMPLEX, \n",
    "                   #1, (0,0,255), 2, cv.LINE_AA)\n",
    "    # Flip the image horizontally for a selfie-view display.\n",
    "    image = cv.flip(image, 1)\n",
    "    cv.putText(image, f\"x: {draw_x}, y: {draw_y}\", (10, 50), cv.FONT_HERSHEY_SIMPLEX, \n",
    "                   1, (0,0,255), 2, cv.LINE_AA)\n",
    "    #cv.putText(image, className, (10, 50), cv.FONT_HERSHEY_SIMPLEX, \n",
    "                   #1, (0,0,255), 2, cv.LINE_AA)\n",
    "\n",
    "    cv.imshow('MediaPipe Hands', image)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "\n",
    "\"\"\"\n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv.imshow('frame', frame)\n",
    "    key = cv.waitKey(1) & 0xFF\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "\"\"\"\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e4f8dfdae44daabd2cd5d3fad68f3ac45961c519890548e4a4fc68f068066b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
